# Roadmap

1. Reward estimation
    - More expressive configurability
    - Normalization
    - Generalized advantage estimation
2. Memory architecture
    - Optimize retrieval of sequences
    - Use TensorArray
    - Improve other limitations
3. RNN policies
    - Extend configurability
    - Allow recurrent baselines
    - More RNN modules, incl Transformer
4. Reward estimation extensions
    - Auxiliary losses
    - Curiosity
    - Imitation learning
    - Distributional perspective
5. State/action modeling
    - Sequence states/actions
    - State-dependent actions
    - Conditional/hierarchical actions
6. CARLA environment
    - Docs and assertions 
    - World's map loading (e.g. random, specific, etc.)
    - Weather support
    - Pretraining and Free play (e.g. for data collection)
    - State space with a temporal component.
    - ...
7. To be determined...
